// Step 1: Extract cntrprty_client_lkpid from pos_frame and collect into a List[String]
val cntrprtyClientList = pos_frame
  .select("cntrprty_client_lkpid")
  .as[String]
  .collect()
  .toList

// Step 2: Filter the rdr_client_full_name based on cntrprtyClientList
val filteredRdrClientFullName = rdr_client_full_name
  .filter(col("clt_oid").isin(cntrprtyClientList: _*))

// Step 3a: Group by clt_credit_ult_prnt and collect distinct values
val creditUltPrntDF = filteredRdrClientFullName
  .groupBy("clt_credit_ult_prnt")
  .agg(collect_list("clt_oid").as("distinct_clt_oid_credit"))

// Step 3b: Group by clt_prf_ult_prnt and collect distinct values
val prfUltPrntDF = filteredRdrClientFullName
  .groupBy("clt_prf_ult_prnt")
  .agg(collect_list("clt_oid").as("distinct_clt_oid_profit"))

// Step 3c: Group by clt_oid and collect distinct values
val oidDF = filteredRdrClientFullName
  .groupBy("clt_oid")
  .agg(collect_list("clt_oid").as("distinct_clt_oid"))

// Step 4: Merge the three lists (distinct_clt_oid_credit, distinct_clt_oid_profit, distinct_clt_oid) into a single list
import org.apache.spark.sql.functions._

val mergedListDF = creditUltPrntDF
  .select(explode(col("distinct_clt_oid_credit")).as("clt_oid"))
  .union(prfUltPrntDF.select(explode(col("distinct_clt_oid_profit")).as("clt_oid")))
  .union(oidDF.select(explode(col("distinct_clt_oid")).as("clt_oid")))
  .distinct() // Ensure distinct values in the merged list

// Collect the merged distinct list into a List[String]
val mergedClientOidList = mergedListDF
  .select("clt_oid")
  .as[String]
  .collect()
  .toList

// Step 5: Use the merged list to filter rdr_client_full_name
val finalRdrClientFullName = rdr_client_full_name
  .filter(col("clt_oid").isin(mergedClientOidList: _*))

// Show the filtered results
finalRdrClientFullName.show(truncate = false)
